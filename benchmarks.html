<!DOCTYPE html>
<!--[if IE]><![endif]-->
<html>
  
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>Benchmarks | .NEXT </title>
    <meta name="viewport" content="width=device-width">
    <meta name="title" content="Benchmarks | .NEXT ">
    <meta name="generator" content="docfx 2.56.1.0">
    
    <link rel="shortcut icon" href="fav.ico">
    <link rel="stylesheet" href="styles/docfx.vendor.css">
    <link rel="stylesheet" href="styles/docfx.css">
    <link rel="stylesheet" href="styles/main.css">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
    <meta property="docfx:navrel" content="toc.html">
    <meta property="docfx:tocrel" content="toc.html">
    
    
    
  </head>  <body data-spy="scroll" data-target="#affix" data-offset="120">
    <div id="wrapper">
      <header>
        
        <nav id="autocollapse" class="navbar navbar-inverse ng-scope" role="navigation">
          <div class="container">
            <div class="navbar-header">
              <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
              
              <a class="navbar-brand" href="index.html">
                <img id="logo" class="svg" src="doc_logo.png" alt="">
              </a>
            </div>
            <div class="collapse navbar-collapse" id="navbar">
              <form class="navbar-form navbar-right" role="search" id="search">
                <div class="form-group">
                  <input type="text" class="form-control" id="search-query" placeholder="Search" autocomplete="off">
                </div>
              </form>
            </div>
          </div>
        </nav>
        
        <div class="subnav navbar navbar-default">
          <div class="container hide-when-search" id="breadcrumb">
            <ul class="breadcrumb">
              <li></li>
            </ul>
          </div>
        </div>
      </header>
      <div role="main" class="container body-content hide-when-search">
        <div class="article row grid">
          <div class="col-md-10">
            <article class="content wrap" id="_content" data-uid="">
<h1 id="benchmarks">Benchmarks</h1>

<p>Microbenchmarks are important part of DotNext library to prove than important features can speed up performance of your application or, at least, is not slowing down it.</p>
<p>The configuration of all benchmarks:</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Configuration</th>
</tr>
</thead>
<tbody>
<tr>
<td>Host</td>
<td>.NET Core 3.1.5 (CoreCLR 4.700.20.26901, CoreFX 4.700.20.27001), X64 RyuJIT</td>
</tr>
<tr>
<td>Job</td>
<td>.NET Core 3.1.5 (CoreCLR 4.700.20.26901, CoreFX 4.700.20.27001), X64 RyuJIT</td>
</tr>
<tr>
<td>LaunchCount</td>
<td>1</td>
</tr>
<tr>
<td>RunStrategy</td>
<td>Throughput</td>
</tr>
<tr>
<td>OS</td>
<td>Ubuntu 18.04.4</td>
</tr>
<tr>
<td>CPU</td>
<td>Intel Core i7-6700HQ CPU 2.60GHz (Skylake)</td>
</tr>
<tr>
<td>Number of CPUs</td>
<td>1</td>
</tr>
<tr>
<td>Physical Cores</td>
<td>4</td>
</tr>
<tr>
<td>Logical Cores</td>
<td>8</td>
</tr>
<tr>
<td>RAM</td>
<td>24 GB</td>
</tr>
</tbody>
</table>
<p>You can run benchmarks using <code>Bench</code> build configuration as follows:</p>
<pre><code class="lang-bash">cd &lt;dotnext-clone-path&gt;/src/DotNext.Benchmarks
dotnet run -c Bench
</code></pre>
<h1 id="bitwise-equality">Bitwise Equality</h1>
<p><a href="https://github.com/sakno/DotNext/blob/master/src/DotNext.Benchmarks/BitwiseEqualityBenchmark.cs">This benchmark</a> compares performance of <a href="api/DotNext.BitwiseComparer-1.html">BitwiseComparer&lt;T&gt;.Equals</a> with overloaded equality <code>==</code> operator. Testing data types: <a href="https://docs.microsoft.com/en-us/dotnet/api/system.guid">Guid</a> and custom value type with multiple fields.</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Mean</th>
<th>Error</th>
<th>StdDev</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>BitwiseComparer&lt;Guid&gt;.Equals</code></td>
<td>3.3381 ns</td>
<td>0.0323 ns</td>
<td>0.0287 ns</td>
</tr>
<tr>
<td><code>Guid.Equals</code></td>
<td>2.1275 ns</td>
<td>0.0126 ns</td>
<td>0.0112 ns</td>
</tr>
<tr>
<td><code>ReadOnlySpan.SequenceEqual</code> for <code>Guid</code></td>
<td>4.5505 ns</td>
<td>0.0477 ns</td>
<td>0.0423 ns</td>
</tr>
<tr>
<td><code>BitwiseComparer&lt;LargeStruct&gt;.Equals</code></td>
<td>16.0034 ns</td>
<td>0.3494 ns</td>
<td>0.5542 ns</td>
</tr>
<tr>
<td><code>LargeStruct.Equals</code></td>
<td>45.1184 ns</td>
<td>0.0946 ns</td>
<td>0.0884 ns</td>
</tr>
<tr>
<td><code>ReadOnlySpan.SequenceEqual</code> for <code>LargeStruct</code></td>
<td>24.8373 ns</td>
<td>0.4922 ns</td>
<td>0.4364 ns</td>
</tr>
</tbody>
</table>
<p>Bitwise equality method has the better performance than field-by-field equality check especially for large value types because <code>BitwiseEquals</code> utilizes low-level optimizations performed by .NET Core according with underlying hardware such as SIMD. Additionally, it uses <a href="https://en.wikipedia.org/wiki/Data_structure_alignment">aligned memory access</a> in constrast to <a href="https://docs.microsoft.com/en-us/dotnet/api/system.memoryextensions.sequenceequal">SequenceEqual</a> method.</p>
<h1 id="equality-of-arrays">Equality of Arrays</h1>
<p><a href="https://github.com/sakno/DotNext/blob/master/src/DotNext.Benchmarks/ArrayEqualityBenchmark.cs">This benchmark</a> compares performance of <a href="https://docs.microsoft.com/en-us/dotnet/api/system.memoryextensions.sequenceequal#System_MemoryExtensions_SequenceEqual__1_System_ReadOnlySpan___0__System_ReadOnlySpan___0__">ReadOnlySpan.SequenceEqual</a>, <a href="api/DotNext.OneDimensionalArray.html">OneDimensionalArray.BitwiseEquals</a> and manual equality check between two arrays using <code>for</code> loop. The benchmark is applied to the array of <a href="https://docs.microsoft.com/en-us/dotnet/api/system.guid">Guid</a> elements.</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Mean</th>
<th>Error</th>
<th>StdDev</th>
<th>Median</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Guid[].BitwiseEquals</code>, small arrays (~10 elements)</td>
<td>9.039 ns</td>
<td>0.0426 ns</td>
<td>0.0399 ns</td>
<td>9.042 ns</td>
</tr>
<tr>
<td><code>ReadOnlySpan&lt;Guid&gt;.SequenceEqual</code>, small arrays (~10 elements)</td>
<td>45.571 ns</td>
<td>0.1440 ns</td>
<td>0.1276 ns</td>
<td>45.569 ns</td>
</tr>
<tr>
<td><code>for</code> loop, small arrays (~10 elements)</td>
<td>63.031 ns</td>
<td>0.1057 ns</td>
<td>0.0937 ns</td>
<td>63.064 ns</td>
</tr>
<tr>
<td><code>Guid[].BitwiseEquals</code>, large arrays (~100 elements)</td>
<td>47.892 ns</td>
<td>0.2260 ns</td>
<td>0.2004 ns</td>
<td>47.893 ns</td>
</tr>
<tr>
<td><code>ReadOnlySpan&lt;Guid&gt;.SequenceEqual</code>, large arrays (~100 elements)</td>
<td>381.872 ns</td>
<td>7.4653 ns</td>
<td>11.1737 ns</td>
<td>375.948 ns</td>
</tr>
<tr>
<td><code>for</code> loop, large arrays (~100 elements)</td>
<td>631.655 ns</td>
<td>12.4212 ns</td>
<td>19.7013 ns</td>
<td>634.035 ns</td>
</tr>
</tbody>
</table>
<p>Bitwise equality is an absolute winner for equality check between arrays of any size.</p>
<h1 id="bitwise-hash-code">Bitwise Hash Code</h1>
<p><a href="https://github.com/sakno/DotNext/blob/master/src/DotNext.Benchmarks/BitwiseHashCodeBenchmark.cs">This benchmark</a> compares performance of <a href="api/DotNext.BitwiseComparer-1.html">BitwiseComparer&lt;T&gt;.GetHashCode</a> and <code>GetHashCode</code> instance method for the types <a href="https://docs.microsoft.com/en-us/dotnet/api/system.guid">Guid</a> and custom value type with multiple fields.</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Mean</th>
<th>Error</th>
<th>StdDev</th>
<th>Median</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Guid.GetHashCode</code></td>
<td>1.578 ns</td>
<td>0.0328 ns</td>
<td>0.0540 ns</td>
<td>1.570 ns</td>
</tr>
<tr>
<td><code>BitwiseComparer&lt;Guid&gt;.GetHashCode</code></td>
<td>7.288 ns</td>
<td>0.1816 ns</td>
<td>0.3084 ns</td>
<td>7.454 ns</td>
</tr>
<tr>
<td><code>BitwiseComparer&lt;LargeStructure&gt;.GetHashCode</code></td>
<td>40.471 ns</td>
<td>0.1063 ns</td>
<td>0.0994 ns</td>
<td>40.445 ns</td>
</tr>
<tr>
<td><code>LargeStructure.GetHashCode</code></td>
<td>27.826 ns</td>
<td>0.4569 ns</td>
<td>0.5611 ns</td>
<td>27.759 ns</td>
</tr>
</tbody>
</table>
<p>Bitwise hash code algorithm is slower than JIT optimizations introduced by .NET Core 3.1 but still convenient in complex cases.</p>
<h1 id="bytes-to-hex">Bytes to Hex</h1>
<p><a href="https://github.com/sakno/DotNext/blob/master/src/DotNext.Benchmarks/HexConversionBenchmark.cs">This benchmark</a> demonstrates performance of <code>DotNext.Span.ToHex</code> extension method that allows to convert arbitrary set of bytes into hexadecimal form. It is compatible with<code>Span&lt;T&gt;</code> data type in constrast to <a href="https://docs.microsoft.com/en-us/dotnet/api/system.bitconverter.tostring">BitConverter.ToString</a> method.</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Num of Bytes</th>
<th>Mean</th>
<th>Error</th>
<th>StdDev</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>BitConverter.ToString</code></td>
<td>16 bytes</td>
<td>70.23 ns</td>
<td>0.448 ns</td>
<td>0.419 ns</td>
</tr>
<tr>
<td><code>Span.ToHex</code></td>
<td>16 bytes</td>
<td>71.96 ns</td>
<td>0.507 ns</td>
<td>0.450 ns</td>
</tr>
<tr>
<td><code>BitConverter.ToString</code></td>
<td>64 bytes</td>
<td>242.70 ns</td>
<td>1.423 ns</td>
<td>1.111 ns</td>
</tr>
<tr>
<td><code>Span.ToHex</code></td>
<td>64 bytes</td>
<td>151.06 ns</td>
<td>2.869 ns</td>
<td>3.730 ns</td>
</tr>
<tr>
<td><code>BitConverter.ToString</code></td>
<td>128 bytes</td>
<td>481.28 ns</td>
<td>1.176 ns</td>
<td>1.042 ns</td>
</tr>
<tr>
<td><code>Span.ToHex</code></td>
<td>128 bytes</td>
<td>253.64 ns</td>
<td>5.092 ns</td>
<td>6.622 ns</td>
</tr>
<tr>
<td><code>BitConverter.ToString</code></td>
<td>256 bytes</td>
<td>936.35 ns</td>
<td>18.775 ns</td>
<td>23.745 ns</td>
</tr>
<tr>
<td><code>Span.ToHex</code></td>
<td>256 bytes</td>
<td>467.52 ns</td>
<td>1.321 ns</td>
<td>1.103 ns</td>
</tr>
</tbody>
</table>
<p><code>Span.ToHex</code> demonstrates the best performance especially for large arrays.</p>
<h1 id="fast-reflection">Fast Reflection</h1>
<p>The next series of benchmarks demonstrate performance of strongly typed reflection provided by DotNext Reflection library.</p>
<h2 id="property-getter">Property Getter</h2>
<p><a href="https://github.com/sakno/DotNext/blob/master/src/DotNext.Benchmarks/Reflection/PropertyGetterReflectionBenchmark.cs">This benchmark</a> demonstrates overhead of getting instance property value caused by different mechanisms:</p>
<ol>
<li>Using <a href="https://github.com/mgravell/fast-member">FastMember</a> library</li>
<li>Using strongly typed reflection from DotNext Reflection library: <code>Type&lt;IndexOfCalculator&gt;.Property&lt;int&gt;.RequireGetter</code></li>
<li>Using strongly typed reflection from DotNext Reflection library using special delegate type <code>Function&lt;object, ValueTuple, object&gt;</code>. It is assumed that instance type and property type is not known at compile type (th) so the delegate performs type check on every call.</li>
<li>Classic .NET reflection</li>
</ol>
<table>
<thead>
<tr>
<th>Method</th>
<th>Mean</th>
<th>Error</th>
<th>StdDev</th>
<th>Median</th>
</tr>
</thead>
<tbody>
<tr>
<td>Direct call</td>
<td>11.41 ns</td>
<td>0.080 ns</td>
<td>0.067 ns</td>
<td>11.42 ns</td>
</tr>
<tr>
<td>Reflection with DotNext using delegate type <code>MemberGetter&lt;IndexOfCalculator, int&gt;</code></td>
<td>12.71 ns</td>
<td>0.196 ns</td>
<td>0.184 ns</td>
<td>12.64 ns</td>
</tr>
<tr>
<td>Reflection with DotNext using <code>DynamicInvoker</code></td>
<td>21.99 ns</td>
<td>0.046 ns</td>
<td>0.043 ns</td>
<td>21.98 ns</td>
</tr>
<tr>
<td>Reflection with DotNext using delegate type <code>Function&lt;object, ValueTuple, object&gt;</code></td>
<td>21.98 ns</td>
<td>0.072 ns</td>
<td>0.060 ns</td>
<td>21.97 ns</td>
</tr>
<tr>
<td><code>ObjectAccess</code> class from <em>FastMember</em> library</td>
<td>52.67 ns</td>
<td>0.120 ns</td>
<td>0.112 ns</td>
<td>52.67 ns</td>
</tr>
<tr>
<td>.NET reflection</td>
<td>52.67 ns</td>
<td>0.120 ns</td>
<td>0.112 ns</td>
<td>52.67 ns</td>
</tr>
</tbody>
</table>
<p>Strongly typed reflection provided by DotNext Reflection library has the same performance as direct call.</p>
<h2 id="instance-method-call">Instance Method Call</h2>
<p><a href="https://github.com/sakno/DotNext/blob/master/src/DotNext.Benchmarks/Reflection/StringMethodReflectionBenchmark.cs">This benchmark</a> demonstrates overhead of calling instance method <code>IndexOf</code> of type <strong>string</strong> caused by different mechanisms:</p>
<ol>
<li>Using strongly typed reflection from DotNext Reflection library: <code>Type&lt;string&gt;.Method&lt;char, int&gt;.Require&lt;int&gt;(nameof(string.IndexOf))</code></li>
<li>Using strongly typed reflection from DotNext Reflection library using special delegate type: <code>Type&lt;string&gt;.RequireMethod&lt;(char, int), int&gt;(nameof(string.IndexOf));</code></li>
<li>Using strongly typed reflection from DotNext Reflection library using special delegate type: <code>Function&lt;object, (object, object), object&gt;</code>. It is assumed that types of all parameters are not known at compile time.</li>
<li>Classic .NET reflection</li>
</ol>
<p>The benchmark uses series of different strings to run the same set of tests. Worst case means that character lookup is performed for a string that doesn't contain the given character. Best case means that character lookup is performed for a string that has the given character.</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Condition</th>
<th>Mean</th>
<th>Error</th>
<th>StdDev</th>
</tr>
</thead>
<tbody>
<tr>
<td>Direct call</td>
<td>Empty String</td>
<td>6.321 ns</td>
<td>0.1605 ns</td>
<td>0.1784 ns</td>
</tr>
<tr>
<td>Direct call</td>
<td>Best Case</td>
<td>9.329 ns</td>
<td>0.0867 ns</td>
<td>0.0724 ns</td>
</tr>
<tr>
<td>Direct call</td>
<td>Worst Case</td>
<td>12.657 ns</td>
<td>0.1746 ns</td>
<td>0.1633 ns</td>
</tr>
<tr>
<td>Reflection with DotNext using delegate type <code>Func&lt;string, char, int, int&gt;</code></td>
<td>Empty String</td>
<td>8.017 ns</td>
<td>0.0424 ns</td>
<td>0.0331 ns</td>
</tr>
<tr>
<td>Reflection with DotNext using delegate type <code>Func&lt;string, char, int, int&gt;</code></td>
<td>Best Case</td>
<td>12.418 ns</td>
<td>0.0512 ns</td>
<td>0.0479 ns</td>
</tr>
<tr>
<td>Reflection with DotNext using delegate type <code>Func&lt;string, char, int, int&gt;</code></td>
<td>Worst Case</td>
<td>18.113 ns</td>
<td>0.0588 ns</td>
<td>0.0550 ns</td>
</tr>
<tr>
<td>Reflection with DotNext using delegate type <code>Function&lt;string, (char, int), int&gt;</code></td>
<td>Empty String</td>
<td>12.389 ns</td>
<td>0.0227 ns</td>
<td>0.0202 ns</td>
</tr>
<tr>
<td>Reflection with DotNext using delegate type <code>Function&lt;string, (char, int), int&gt;</code></td>
<td>Best Case</td>
<td>17.252 ns</td>
<td>0.0729 ns</td>
<td>0.0682 ns</td>
</tr>
<tr>
<td>Reflection with DotNext using delegate type <code>Function&lt;string, (char, int), int&gt;</code></td>
<td>Worst Case</td>
<td>20.930 ns</td>
<td>0.0226 ns</td>
<td>0.0200 ns</td>
</tr>
<tr>
<td>Reflection with DotNext using delegate type <code>Function&lt;object, (object, object), object&gt;</code></td>
<td>Empty String</td>
<td>30.871 ns</td>
<td>0.1307 ns</td>
<td>0.1222 ns</td>
</tr>
<tr>
<td>Reflection with DotNext using delegate type <code>Function&lt;object, (object, object), object&gt;</code></td>
<td>Best Case</td>
<td>33.069 ns</td>
<td>0.5989 ns</td>
<td>1.0006 ns</td>
</tr>
<tr>
<td>Reflection with DotNext using delegate type <code>Function&lt;object, (object, object), object&gt;</code></td>
<td>Worst Case</td>
<td>35.981 ns</td>
<td>0.7064 ns</td>
<td>0.6938 ns</td>
</tr>
<tr>
<td>.NET reflection</td>
<td>Empty String</td>
<td>311.787 ns</td>
<td>1.0205 ns</td>
<td>0.9546 ns</td>
</tr>
<tr>
<td>.NET reflection</td>
<td>Best Case</td>
<td>318.686 ns</td>
<td>6.2622 ns</td>
<td>6.4308 ns</td>
</tr>
<tr>
<td>.NET reflection</td>
<td>Worst Case</td>
<td>332.189 ns</td>
<td>1.3130 ns</td>
<td>1.2282 ns</td>
</tr>
</tbody>
</table>
<p>DotNext Reflection library offers the best result in case when delegate type exactly matches to the reflected method with small overhead measured in a few nanoseconds.</p>
<h2 id="static-method-call">Static Method Call</h2>
<p><a href="https://github.com/sakno/DotNext/blob/master/src/DotNext.Benchmarks/Reflection/TryParseReflectionBenchmark.cs">This benchmark</a> demonstrates overhead of calling static method <code>TryParse</code> of type <strong>decimal</strong> caused by different mechanisms:</p>
<ol>
<li>Using strongly typed reflection from DotNext Reflection library: <code>Type&lt;decimal&gt;.Method.Get&lt;TryParseDelegate&gt;(nameof(decimal.TryParse), MethodLookup.Static)</code>. The delegate type exactly matches to the reflected method signature: <code>delegate bool TryParseDelegate(string text, out decimal result)</code></li>
<li>Using strongly typed reflection from DotNext Reflection library using special delegate type: <code>Function&lt;(string text, decimal result), bool&gt;</code></li>
<li>Using strongly typed reflection from DotNext Reflection library using special delegate type: <code>Function&lt;(object text, object result), object&gt;</code>. It is assumed that types of all parameters are not known at compile time.</li>
<li>Classic .NET reflection</li>
</ol>
<table>
<thead>
<tr>
<th>Method</th>
<th>Mean</th>
<th>Error</th>
<th>StdDev</th>
</tr>
</thead>
<tbody>
<tr>
<td>Direct call</td>
<td>124.1 ns</td>
<td>1.98 ns</td>
<td>2.78 ns</td>
</tr>
<tr>
<td>Reflection with DotNext using delegate type <code>TryParseDelegate</code></td>
<td>133.5 ns</td>
<td>0.28 ns</td>
<td>0.25 ns</td>
</tr>
<tr>
<td>Reflection with DotNext using delegate type <code>Function&lt;(string text, decimal result), bool&gt;</code></td>
<td>142.8 ns</td>
<td>0.23 ns</td>
<td>0.21 ns</td>
</tr>
<tr>
<td>Reflection with DotNext using delegate type <code>Function&lt;(object text, object result), object&gt;</code></td>
<td>182.4 ns</td>
<td>0.77 ns</td>
<td>0.68 ns</td>
</tr>
<tr>
<td>.NET reflection</td>
<td>517.0 ns</td>
<td>1.53 ns</td>
<td>1.43 ns</td>
</tr>
</tbody>
</table>
<p>Strongly typed reflection provided by DotNext Reflection library has the same performance as direct call.</p>
<h1 id="atomic-access-to-arbitrary-value-type">Atomic Access to Arbitrary Value Type</h1>
<p><a href="https://github.com/sakno/DotNext/blob/master/src/DotNext.Benchmarks/Threading/AtomicContainerBenchmark.cs">This benchmark</a> compares performance of <a href="api/DotNext.Threading.Atomic-1.html">Atomic&lt;T&gt;</a> and Synchronized methods. The implementation of the benchmark contains concurrent read/write threads to ensure that lock contention is in place.</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Mean</th>
<th>Error</th>
<th>StdDev</th>
<th>Median</th>
</tr>
</thead>
<tbody>
<tr>
<td>Atomic</td>
<td>336.8 us</td>
<td>9.20 us</td>
<td>87.27 us</td>
<td>318.1 us</td>
</tr>
<tr>
<td>Synchronized</td>
<td>902.3 us</td>
<td>8.32 us</td>
<td>78.44 us</td>
<td>896.4 us</td>
</tr>
<tr>
<td>SpinLock</td>
<td>1,814.2 us</td>
<td>55.27 us</td>
<td>518.56 us</td>
<td>1,715.9 us</td>
</tr>
</tbody>
</table>
<h1 id="value-delegate">Value Delegate</h1>
<p><a href="https://github.com/sakno/DotNext/blob/master/src/DotNext.Benchmarks/FunctionPointerBenchmark.cs">This benchmark</a> compares performance of indirect method call using classic delegates from .NET and <a href="features/core/valued.html">value delegates</a>.</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Mean</th>
<th>Error</th>
<th>StdDev</th>
</tr>
</thead>
<tbody>
<tr>
<td>Instance method, regular delegate, has implicit <strong>this</strong></td>
<td>0.9273 ns</td>
<td>0.0072 ns</td>
<td>0.0060 ns</td>
</tr>
<tr>
<td>Instance method, Value Delegate, has implicit <strong>this</strong></td>
<td>1.8824 ns</td>
<td>0.0495 ns</td>
<td>0.0463 ns</td>
</tr>
<tr>
<td>Static method, regular delegate, large size of param type, no implicitly captured object</td>
<td>14.5560 ns</td>
<td>0.0440 ns</td>
<td>0.0367 ns</td>
</tr>
<tr>
<td>Static method, Value Delegate, large size of param type, no implicitly captured object</td>
<td>15.7549 ns</td>
<td>0.0731 ns</td>
<td>0.0684 ns</td>
</tr>
<tr>
<td>Static method, regular delegate, small size of param type, no implicitly captured object</td>
<td>23.2037 ns</td>
<td>0.3844 ns</td>
<td>0.3408 ns</td>
</tr>
<tr>
<td>Static method, Value Delegate, small size of param type, no implicitly captured object</td>
<td>21.8213 ns</td>
<td>0.1073 ns</td>
<td>0.0896 ns</td>
</tr>
</tbody>
</table>
<p><em>Large size of param type</em> means that the type of the parameter is larger than 64 bit.</p>
<p>Interpretation of benchmark results:</p>
<ul>
<li><em>Proxy</em> mode of Value Delegate adds a small overhead in comparison with regular delegate</li>
<li>If the type of the parameter is less than or equal to the size of CPU register then Value Delegate offers the best performance</li>
<li>If the type of the parameter is greater than the size of CPU register then Value Delegate is slower than regular delegate</li>
</ul>
<h1 id="file-buffering-writer">File-buffering Writer</h1>
<p><a href="https://github.com/sakno/dotNext/blob/master/src/DotNext.Benchmarks/IO/FileBufferingWriterBenchmark.cs">This benchmark</a> compares performance of <a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.webutilities.filebufferingwritestream">FileBufferingWriteStream</a> from ASP.NET Core and <a href="api/DotNext.IO.FileBufferingWriter.html">FileBufferingWriter</a> from .NEXT library.</p>
<p>Both classes switching from in-memory buffer to file-based buffer during benchmark execution. Note that benchmark result highly depends on disk I/O performance. The following results were obtained using NVMe SSD.</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Mean</th>
<th>Error</th>
<th>StdDev</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>FileBufferingWriter</code> in synchronous mode</td>
<td>877.5 us</td>
<td>17.13 us</td>
<td>18.33 us</td>
</tr>
<tr>
<td><code>FileBufferingWriteStream</code> in synchronous mode</td>
<td>26,396.0 us</td>
<td>943.21 us</td>
<td>2,751.40 us</td>
</tr>
<tr>
<td><code>FileBufferingWriter</code> in asynchronous mode</td>
<td>14,526.9 us</td>
<td>1,888.52 us</td>
<td>5,568.36 us</td>
</tr>
<tr>
<td><code>FileBufferingWriteStream</code> in asynchronous mode</td>
<td>16,819.3 us</td>
<td>1,074.98 us</td>
<td>3,169.59 us</td>
</tr>
</tbody>
</table>
<p><code>FileBufferingWriter</code> is a winner in synchronous scenario because it has native support for synchronous mode in contrast to <code>FileBufferingWriteStream</code>.</p>
</article>
          </div>
          
          <div class="hidden-sm col-md-2" role="complementary">
            <div class="sideaffix">
              <div class="contribution">
                <ul class="nav">
                  <li>
                    <a href="https://github.com/sakno/dotNext/blob/gh-pages/docs/benchmarks.md/#L1" class="contribution-link">Improve this Doc</a>
                  </li>
                </ul>
              </div>
              <nav class="bs-docs-sidebar hidden-print hidden-xs hidden-sm affix" id="affix">
              <!-- <p><a class="back-to-top" href="#top">Back to top</a><p> -->
              </nav>
            </div>
          </div>
        </div>
      </div>
      
      <footer>
        <div class="grad-bottom"></div>
        <div class="footer">
          <div class="container">
            <span class="pull-right">
              <a href="#top">Back to top</a>
            </span>
            
            <span>Generated by <strong>DocFX</strong></span>
          </div>
        </div>
      </footer>
    </div>
    
    <script type="text/javascript" src="styles/docfx.vendor.js"></script>
    <script type="text/javascript" src="styles/docfx.js"></script>
    <script type="text/javascript" src="styles/main.js"></script>
  </body>
</html>
